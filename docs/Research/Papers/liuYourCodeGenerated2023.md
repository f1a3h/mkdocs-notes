---
title: liuYourCodeGenerated2023
tags:
  - Papers
---

## 1. Abstract & Info

### 1.1 Abstract

Program synthesis has been long studied with recent approaches focused on directly using the power of Large Language Models (LLMs) to generate code. Programming benchmarks, with curated synthesis problems and test-cases, are used to measure the performance of various LLMs on code synthesis. However, these test-cases can be limited in both quantity and quality for fully assessing the functional correctness of the generated code. Such limitation in the existing benchmarks begs the following question: In the era of LLMs, is the code generated really correct? To answer this, we propose EvalPlus -- a code synthesis evaluation framework to rigorously benchmark the functional correctness of LLM-synthesized code. EvalPlus augments a given evaluation dataset with large amounts of test-cases newly produced by an automatic test input generator, powered by both LLM- and mutation-based strategies. While EvalPlus is general, we extend the test-cases of the popular HumanEval benchmark by 80x to build HumanEval+. Our extensive evaluation across 26 popular LLMs (e.g., GPT-4 and ChatGPT) demonstrates that HumanEval+ is able to catch significant amounts of previously undetected wrong code synthesized by LLMs, reducing the pass@k by up-to 19.3-28.9%. We also surprisingly found that test insufficiency can lead to mis-ranking. For example, both WizardCoder-CodeLlama and Phind-CodeLlama now outperform ChatGPT on HumanEval+, while none of them could on HumanEval. Our work not only indicates that prior popular code synthesis evaluation results do not accurately reflect the true performance of LLMs for code synthesis, but also opens up a new direction to improve such programming benchmarks through automated testing. We have open-sourced our tools, enhanced datasets as well as all LLM-generated code at https://github.com/evalplus/evalplus to facilitate and accelerate future LLM-for-code research.

### 1.2 Info

Authors: Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, Lingming Zhang
DOI: 10.48550/arXiv.2305.01210
Publication: 
Zotero: [arXiv Fulltext PDF](zotero://select/library/items/UQAKANKI)
Date: 2023-10-30

## 2. Annotation
%% begin annotations %%
Annotated Textï¼š[uses ChatGPT [48] to generate a set of high-quality seed inputs](zotero://open-pdf/library/items/UQAKANKI?page=2&annotation=W56PAUW7)
Commentï¼šğŸ”¤ä½¿ç”¨ChatGPT [ 48 ]ç”Ÿæˆä¸€ç»„é«˜è´¨é‡çš„ç§å­è¾“å…¥ğŸ”¤



Annotated Textï¼š[type-aware mutation to efficiently generate a large number of additional test input](zotero://open-pdf/library/items/UQAKANKI?page=2&annotation=EJEYUD8J)
Commentï¼šğŸ”¤ç±»å‹æ„ŸçŸ¥å˜å¼‚èƒ½å¤Ÿé«˜æ•ˆåœ°äº§ç”Ÿå¤§é‡é¢å¤–çš„æµ‹è¯•è¾“å…¥ğŸ”¤



Annotated Textï¼š[differential testing](zotero://open-pdf/library/items/UQAKANKI?page=2&annotation=JQ2LKE5C)
Commentï¼šğŸ”¤å·®åˆ†æ£€æµ‹ğŸ”¤



Annotated Textï¼š[greedy set cover algorithm](zotero://open-pdf/library/items/UQAKANKI?page=3&annotation=RJQ7V4A3)
Commentï¼šğŸ”¤è´ªå¿ƒé›†åˆè¦†ç›–ç®—æ³•ğŸ”¤







Annotated Textï¼š[LLM-based strategy to bootstrap the test generator with high-quality seed inputs and then further extends large amounts of inputs via type-aware mutation](zotero://open-pdf/library/items/UQAKANKI?page=3&annotation=QKQWTBEL)
Commentï¼šğŸ”¤åŸºäºLLMçš„ç­–ç•¥ä»¥é«˜è´¨é‡çš„ç§å­è¾“å…¥å¼•å¯¼æµ‹è¯•ç”Ÿæˆå™¨ï¼Œç„¶åé€šè¿‡ç±»å‹æ„ŸçŸ¥å˜å¼‚è¿›ä¸€æ­¥æ‰©å±•å¤§é‡è¾“å…¥ğŸ”¤



Annotated Textï¼š[greedy set covering](zotero://open-pdf/library/items/UQAKANKI?page=3&annotation=GDPEFT9K)
Commentï¼šğŸ”¤è´ªå©ªé›†åˆè¦†ç›–ğŸ”¤





Annotated Textï¼š[the powerful understanding ability of ChatGPT to learn both the valid input formats (e.g., variable types) as well as the desired functionality of the ground-truth solution](zotero://open-pdf/library/items/UQAKANKI?page=4&annotation=D4CCVK4D)
Commentï¼šğŸ”¤ChatGPT å¼ºå¤§çš„ç†è§£èƒ½åŠ›ï¼Œæ—¢å¯ä»¥å­¦ä¹ æœ‰æ•ˆçš„è¾“å…¥æ ¼å¼ï¼ˆä¾‹å¦‚ï¼Œå˜é‡ç±»å‹ï¼‰ï¼Œä¹Ÿå¯ä»¥å­¦ä¹ çœŸå€¼è§£å†³æ–¹æ¡ˆçš„æ‰€éœ€åŠŸèƒ½ğŸ”¤



Annotated Textï¼š[valid even under semantic constraints](zotero://open-pdf/library/items/UQAKANKI?page=4&annotation=734IJN3Z)
Commentï¼šğŸ”¤å³ä½¿åœ¨è¯­ä¹‰çº¦æŸä¸‹ä¹Ÿæœ‰æ•ˆğŸ”¤





Annotated Textï¼š[type-aware input mutation starting from high-quality seed inputs generated by ChatGPT](zotero://open-pdf/library/items/UQAKANKI?page=4&annotation=929FP4V2)
Commentï¼šğŸ”¤ç±»å‹æ„ŸçŸ¥è¾“å…¥çªå˜ä» ChatGPT ç”Ÿæˆçš„é«˜è´¨é‡ç§å­è¾“å…¥å¼€å§‹ğŸ”¤











Annotated Textï¼š[programming by contract [41] philosophy by systematically annotating function pre-conditions in form of code assertions](zotero://open-pdf/library/items/UQAKANKI?page=5&annotation=4P7CRD8Q)
Commentï¼šğŸ”¤å¥‘çº¦ç¼–ç¨‹ [41] å“²å­¦ï¼Œé€šè¿‡ä»¥ä»£ç æ–­è¨€çš„å½¢å¼ç³»ç»Ÿåœ°æ³¨é‡Šå‡½æ•°å‰ææ¡ä»¶ğŸ”¤

%% end annotations %%


%% Import Date: 2024-02-15T12:47:41.675+08:00 %%
